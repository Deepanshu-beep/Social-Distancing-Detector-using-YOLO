{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Project\\Object Recog. with YOLO\n"
     ]
    }
   ],
   "source": [
    "cd F:\\Project\\Object Recog. with YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='F:\\Project\\Object Recog. with YOLO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_Confidence=0.4\n",
    "#Minimum Confidence to filter weak connections\n",
    "NMS_Threshold=0.3\n",
    "#Minimum threshold for Non-Max Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimum Distance between 2 persons required\n",
    "min_Dist=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectPeople(net, frame, ln, personIndx=0):\n",
    "    results=[]\n",
    "    (H,W)=frame.shape[:2]\n",
    "    #Processing frame, and extracting detections using YOLO Algorithm\n",
    "    blob=cv2.dnn.blobFromImage(frame, 1/255.0, (416,416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerOutputs=net.forward(ln)\n",
    "    boxes=[]\n",
    "    confidences=[]\n",
    "    centers=[]\n",
    "    for output in layerOutputs:\n",
    "        for detections in output:\n",
    "            #Getting score for each probability of detection\n",
    "            scores=detections[5:]\n",
    "            #Getting the Prediction with Highest Probability\n",
    "            classID=np.argmax(scores)\n",
    "            confidence=scores[classID]\n",
    "            #Checking if the Highest Probability is that of a person\n",
    "            if classID==personIndx and confidence>min_Confidence:\n",
    "                #Getting location of person\n",
    "                box=detections[0:4]*np.array([W,H,W,H])\n",
    "                (centerX,centerY,width,height)=box.astype('int')\n",
    "                top_leftX=int(centerX-(width/2))\n",
    "                top_leftY=int(centerY-(height/2))\n",
    "                boxes.append([top_leftX,top_leftY,int(width),int(height)])\n",
    "                centers.append((centerX,centerY))\n",
    "                confidences.append(float(confidence))\n",
    "    #Applying non-max suppression to avoid Extra Boxes\n",
    "    non_max_suppression=cv2.dnn.NMSBoxes(boxes, confidences, min_Confidence, NMS_Threshold)\n",
    "    if len(non_max_suppression)>0:\n",
    "        for i in non_max_suppression.flatten():\n",
    "            (x1,y1,x2,y2)=(boxes[i][0],boxes[i][1],boxes[i][2]+boxes[i][0],boxes[i][3]+boxes[i][1])\n",
    "            temp=(confidences[i],(x1,y1,x2,y2),centers[i])\n",
    "            results.append(temp)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "from scipy.spatial import distance as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required files for YOLO\n",
    "labelsPath='F:\\Project\\Object Recog. with YOLO\\coco.names'\n",
    "labels=open(labelsPath).read().strip().split('\\n')\n",
    "weightPaths='F:\\Project\\Object Recog. with YOLO\\yolov3.weights'\n",
    "configPath='F:\\Project\\Object Recog. with YOLO\\yolov3.cfg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating YOLO Model from it's files\n",
    "model=cv2.dnn.readNetFromDarknet(configPath, weightPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Project\\Social Distancing with YOLO\n"
     ]
    }
   ],
   "source": [
    "cd F:\\Project\\Social Distancing with YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp='inp1.mp4'\n",
    "output='output1.avi'\n",
    "display=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln=model.getLayerNames()\n",
    "ln=[ln[i[0]-1] for i in model.getUnconnectedOutLayers()]\n",
    "vs=cv2.VideoCapture(inp)\n",
    "writer=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    (check,frame)=vs.read()\n",
    "    if not check:\n",
    "        break\n",
    "    frame=imutils.resize(frame, width=700)\n",
    "    results=detectPeople(model, frame, ln, labels.index('person'))\n",
    "    violations=set()\n",
    "    #Social Distancing is violated only if Persons>2\n",
    "    if len(results)>=2:\n",
    "        centers=np.array([r[2] for r in results])\n",
    "        D=dt.cdist(centers, centers, metric='euclidean')\n",
    "        for i in range(0,D.shape[0]):\n",
    "            for j in range(i+1,D.shape[1]):\n",
    "                #Checking if Euclidean distance between 2 persons > minimum Distance Required\n",
    "                if (D[i,j]<min_Dist):\n",
    "                    violations.add(i)\n",
    "                    violations.add(j)\n",
    "    for (i, (conf, box, center)) in enumerate(results):\n",
    "        (startX, startY, endX, endY)=box\n",
    "        (centerX,centerY)=center\n",
    "        color=(0,255,0)\n",
    "        #Changing Green color to Red as Social Distancing Violated by this person\n",
    "        if i in violations:\n",
    "            color=(0,0,255)\n",
    "        cv2.rectangle(frame, (startX, startY),(endX,endY),color,2)\n",
    "    #Saving Processed Video as Output\n",
    "    if writer==None and output!='':\n",
    "        fourcc=cv2.VideoWriter_fourcc(*'MJPG')\n",
    "        writer=cv2.VideoWriter(output, fourcc, 25, (frame.shape[1],frame.shape[0]),True)\n",
    "    if writer is not None:\n",
    "        writer.write(frame)\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
